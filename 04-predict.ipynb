{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install openpyxl gensim fasttext===0.9.2 razdel nmslib xlsxwriter razdel","metadata":{"_uuid":"e2e405d9-d96a-49d0-8e08-e2c52aaaf308","_cell_guid":"906e66ed-bb45-44ff-94b1-f38d12f491c9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-17T01:30:11.379999Z","iopub.execute_input":"2022-07-17T01:30:11.380608Z","iopub.status.idle":"2022-07-17T01:30:22.421910Z","shell.execute_reply.started":"2022-07-17T01:30:11.380524Z","shell.execute_reply":"2022-07-17T01:30:22.420310Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"import re, os, tqdm\nfrom catboost import CatBoostClassifier\nimport pandas as pd\nimport numpy as np\nimport fasttext\nimport razdel\nimport nmslib\nimport scipy as sp\nimport joblib, pickle\nfrom itertools import combinations\nfrom tqdm import tqdm, tqdm_notebook\ntqdm.pandas()\n\n#папка с необходимыми файлами для обучения модели\npath = \"/kaggle/input/hacksai-3/\"\ntemp = \"/kaggle/working/\"\n\nrussian_stopwords = open(os.path.join(path, 'stopwords-ru.txt'), 'r').read().split('\\n')\nprod_name_clf = joblib.load(os.path.join(path,'product_group.pkl'))\nanomaly_detector = CatBoostClassifier()\nanomaly_detector.load_model(os.path.join(path,'anomaly_detector.model'))\nreg_clf = fasttext.load_model(os.path.join(path,'reglament_predictor.model'))\nved_thes = pd.read_csv(os.path.join(path,'ved_dict.csv'), sep=';')\nfor code_col in [\"GRUPPA\", \"TOV_POZ\", \"SUB_POZ\", \"VED\", \"RAZDEL\"]:\n    ved_thes.loc[ved_thes[code_col].notna(), code_col] =\\\n        ved_thes.loc[ved_thes[code_col].notna(), code_col].astype(int).astype(str)\nwith open(os.path.join(path,'ved_dict.pickle'), \"rb\") as handle:\n    ved_dict = pickle.load(handle)\npmi_hist = pd.read_csv(os.path.join(path,'pmi_features.csv'), sep=';')\npmi_hist[pmi_hist.columns[:5]] = pmi_hist[pmi_hist.columns[:5]].astype(str)\nindex = nmslib.init(method='napp', space='cosinesimil')\nindex.loadIndex(os.path.join(path,'index_ved'), load_data=True)\n\nindexed_data_dict = joblib.load(os.path.join(path,'index_map.pkl'))\nft_model_v2 = fasttext.load_model(os.path.join(path, 'fb_model_v2.bin'))\n\n\ndef delete_stopwords(s):\n    return ' '.join([word for word in (re.sub(r'[()\\s+]', u' ', s)).split() if word.lower() not in russian_stopwords]).split()\n\n\ndef delete_punctuation(s):\n    symbols = [\n           '\\t', '!','%','&',\"'\",'(',')','*','+',',','-','.', '\\\\', '®',\n           '/', '~','«','\\xad','¯','°','`','±','²','³','·','º', '»', ':',';','<','=','?','@',\n           'É','Ó','Ö','×','Ø','Ü','ä','é','ö','÷','İ','Š','˂','˚','̆','Ι', 'Λ', '[','\\\\',']','_','`',\n          '\\u200e','‐','–', '—', '‘', '’', '“', '”', '•', '…', '‧', '⁰', '₂', '℃', '№', '™', \n           'Ⅰ', 'Ⅱ', 'Ⅲ', 'Ⅳ', '↑', '−', '∞', '≤', '\\uf0d2' '️','（', '）', '，', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'\n          ]\n    \n    return re.sub(r'[{}\\s+]'.format(''.join(symbols)), u' ', s.replace('\\xad', ' '))\n\n\ndef tokenize_with_razdel(text):\n    tokens = [token.text for token in razdel.tokenize(text)]\n    \n    return tokens\n\n\nvectorizer = joblib.load(os.path.join(path,'vectorizer.pkl'))\n\n\ndef get_product_name(data):\n    predicts = prod_name_clf.predict(vectors)\n    return predicts\n    \n    \ndef get_ved(data):    \n    model_ved1 = joblib.load(os.path.join(path,'ved1.pkl'))\n    model_ved2 = joblib.load(os.path.join(path,'ved2.pkl'))\n    model_ved3 = joblib.load(os.path.join(path,'ved3.pkl'))\n    \n    ved1 = model_ved1.predict(data)\n    data_ved2 = np.hstack([data, ved1])\n    ved2 = model_ved2.predict(data_ved2)\n    \n    del data_ved2\n    gc.collect()\n    \n    data_ved3 = np.hstack([data, ved1, ved2])\n    ved3 = model_ved3.predict(data_ved3)\n    \n    return str(ved1)+str(ved2)+str(ved3)\n\n\ndef write_file(data):\n\n    list1 = data[['Номер продукции', 'Общее наименование продукции',\n             'Коды ТН ВЭД ЕАЭС', 'Технические регламенты',\n             'Группа продукции', 'Наличие ошибки']]\n    list1.columns = ['Код', 'Общее наименование продукции',\n            'ТН ВЭД ЕАЭС', 'Технические регламенты',\n            'Группа продукции', 'Наличие ошибки']\n    \n    list2 = data[['Номер продукции', 'Общее наименование продукции',\n      'Коды ТН ВЭД ЕАЭС_predicted', 'Технические регламенты_predicted',\n     'Группа продукции_predicted']]\n    list2.columns = ['Код', 'Общее наименование продукции',\n                    'ТН ВЭД ЕАЭС', 'Технические регламенты',\n                    'Группа продукции']\n    with pd.ExcelWriter('JETFORK_Тесты2.xlsx', engine='xlsxwriter') as writer:\n        list1.to_excel(excel_writer = writer, index = False, sheet_name='Тест1')\n\n        list2.to_excel(excel_writer = writer, index = False, sheet_name='Тест2')\n    \n    \ndef pmi_predict(dataframe, x, y):\n    \"\"\"Calculate PMI for income data based on historical stats.\n    \n    Args:\n        dataframe_hist - historical PMI stats;\n        dataframe - new data to calculation;\n        x - column left;\n        y - column right.\n    Returns:\n        (pd.DataFrame)\n    \"\"\"\n    dataframe = dataframe.merge(\n        pmi_hist[[x, y, f\"pmi_{x}/{y}\"]].drop_duplicates(), \n        on=[x, y], how=\"left\"\n    ).fillna({f\"pmi_{x}/{y}\": -5})\n    return dataframe\n\n\ndef add_ved_info(dataframe):\n    \"\"\" Add VED main categories.\n    \n    Args:\n        dataframe - income data.\n    Returns:\n        (pd.DataFrame)\n    \"\"\"\n    return dataframe.merge(\n        ved_thes[[\"VED\", \"RAZDEL\", \"GRUPPA\", \"TOV_POZ\"]].drop_duplicates() \\\n            .rename(columns={\"VED\": \"Коды ТН ВЭД ЕАЭС\"}) \\\n            .astype(str),\n        on=[\"Коды ТН ВЭД ЕАЭС\"], how=\"left\"\n    ).fillna(\"-1\")\n\n\nIDXS = [\"Номер продукции\"]\nFEATURES = [\"Технические регламенты\", \"Группа продукции\", \"RAZDEL\", \"GRUPPA\", \"TOV_POZ\"]\ndef predict_anomaly(dataframe):\n    \"\"\" Detect outliers in dataframe attributes.\n    \n    Args:\n        dataframe - income data.\n    Returns:\n        (pd.DataFrame)\n    \"\"\"\n    d = dataframe.copy()\n    \n    dataframe = dataframe.dropna(subset=[\"Коды ТН ВЭД ЕАЭС\", \"Технические регламенты\", \"Группа продукции\"])\n    dataframe[\"Коды ТН ВЭД ЕАЭС\"] = dataframe[\"Коды ТН ВЭД ЕАЭС\"].astype(str) \\\n        .str.split(\"; \") \\\n        .apply(set)\n    dataframe[\"Технические регламенты\"] = dataframe[\"Технические регламенты\"].astype(str) \\\n        .str.split(\"; \") \\\n        .apply(set)\n    dataframe[\"Группа продукции\"] = dataframe[\"Группа продукции\"].astype(str) \\\n        .str.split(\"; \") \\\n        .apply(set)\n    dataframe = dataframe[~(dataframe[\"Коды ТН ВЭД ЕАЭС\"].apply(len) > 6)].reset_index(drop=True)\n    dataframe = dataframe[~(dataframe[\"Группа продукции\"].apply(len) > 2)].reset_index(drop=True)\n\n    dataframe = dataframe.explode(\"Коды ТН ВЭД ЕАЭС\") \\\n        .dropna() \\\n        .explode(\"Технические регламенты\") \\\n        .dropna() \\\n        .explode(\"Группа продукции\") \\\n        .dropna() \\\n        .reset_index(drop=True)\n\n    dataframe = add_ved_info(dataframe)\n    dataframe = dataframe[IDXS + FEATURES]\n    \n    for f_1, f_2 in combinations(FEATURES, 2):\n        if f_1 != f_2:\n            dataframe = pmi_predict(dataframe, f_1, f_2)\n    \n    dataframe[\"outlier\"] = anomaly_detector.predict(dataframe[anomaly_detector.feature_names_])\n    d = d.merge(dataframe.groupby(IDXS)[\"outlier\"].max().reset_index(), on=IDXS, how=\"left\")[\"outlier\"].fillna(1).astype(int)\n    return d\n\n\ndef predict_reg(s):\n    \"\"\" Predict tech reg based on product name\n    \n    Args:\n        s - input string.\n    Returns:\n        (str)\n    \"\"\"\n    s = ' '.join(delete_stopwords(delete_punctuation(s)))\n    label = reg_clf.predict(s)[0]\n    return ved_dict.get(label[0][9:].replace('_', ' '))\n\n\ndef get_ved(vectors_ft):\n    neighbours = index.knnQueryBatch(vectors_ft, k=1, num_threads=10)\n    data['index'] = np.array(neighbours)[:, 0].reshape(-1)\n    # data['distance'] = np.array(neighbours)[:, 1].reshape(-1)\n    veds = data['index'].map(indexed_data_dict)\n    return veds.apply(lambda x: ''.join(x))","metadata":{"_uuid":"39a697c1-eeea-4e64-9cf5-fc6f167b3582","_cell_guid":"af0e29ba-4948-4a31-8c2a-bc83f736986f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-17T01:38:26.977025Z","iopub.execute_input":"2022-07-17T01:38:26.977527Z","iopub.status.idle":"2022-07-17T01:38:32.800256Z","shell.execute_reply.started":"2022-07-17T01:38:26.977487Z","shell.execute_reply":"2022-07-17T01:38:32.799006Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(os.path.join(path, 'outlier_whole_preds.csv'), sep=';').drop('outlier', axis=1)\n\ndata['clean_product_name'] = data['Общее наименование продукции'].fillna('') \\\n    .str.lower() \\\n    .apply(lambda x: ' '.join(delete_stopwords(delete_punctuation((x)))))\nvectors = vectorizer.transform(data['clean_product_name'])\nvectors_ft  = np.array([ft_model_v2.get_sentence_vector(text) for text in data['clean_product_name']])\n","metadata":{"_uuid":"9eaa1a86-e07d-46ef-b22e-3d533eb11ced","_cell_guid":"8bc57657-d51e-4e30-9b51-a31d7364ce16","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-17T01:30:27.383593Z","iopub.execute_input":"2022-07-17T01:30:27.383925Z","iopub.status.idle":"2022-07-17T01:30:56.078907Z","shell.execute_reply.started":"2022-07-17T01:30:27.383893Z","shell.execute_reply":"2022-07-17T01:30:56.077699Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"%%time\ndata['Наличие ошибки'] = predict_anomaly(data)\nprint(1)\ndata['Группа продукции_predicted'] = get_product_name(vectors) \nprint(2)\ndata['Технические регламенты_predicted'] = data[\"Общее наименование продукции\"].fillna(\"\").apply(predict_reg)\nprint(3)\ndata['Коды ТН ВЭД ЕАЭС_predicted'] = get_ved(vectors_ft)","metadata":{"_uuid":"0407e485-6e26-4af6-a499-d59c21eb209a","_cell_guid":"6033677f-dd09-4cb3-82df-02b02e48760e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-17T01:30:56.081871Z","iopub.execute_input":"2022-07-17T01:30:56.082238Z","iopub.status.idle":"2022-07-17T01:33:34.342572Z","shell.execute_reply.started":"2022-07-17T01:30:56.082203Z","shell.execute_reply":"2022-07-17T01:33:34.341051Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"write_file(data)","metadata":{"_uuid":"5ff66d7b-8de0-4366-86b4-e7d99dc216f3","_cell_guid":"85747e0a-c173-4387-887c-c42a47fb5b2e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-17T01:38:33.178571Z","iopub.execute_input":"2022-07-17T01:38:33.179409Z","iopub.status.idle":"2022-07-17T01:38:52.346251Z","shell.execute_reply.started":"2022-07-17T01:38:33.179360Z","shell.execute_reply":"2022-07-17T01:38:52.345285Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}